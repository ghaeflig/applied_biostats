---
title: "Report 1: We need a good name for this"
output: 
  pdf_document:
    latex_engine: pdflatex
geometry: 
  - margin=2.5cm
papersize: a4
header-includes:
  - \usepackage{fancyhdr}
  - \pagestyle{fancy}
  - \fancyhead[L]{Report 1}
  - \fancyhead[R]{Monney, Haefliger, Franca, Ferrisse}
fontsize: 12pt
params:
  figwidth: 5
---
```{r, setup, include=FALSE}
# HELP --> https://bookdown.org/yihui/rmarkdown-cookbook/installation.html
# https://bookdown.org/yihui/rmarkdown-cookbook/latex-output.html
# IMPORTANT: you must run this line in your console: tinytex::install_tinytex()
#check that you have pandoc installed
#rmarkdown::find_pandoc()
```

```{=latex}
\thispagestyle{fancy}
```

```{r, include=FALSE}
library(ggplot2)
library(png)
library(knitr)
library(readr)
```

# Introduction/background

```{r, echo=FALSE}
abb <- c("FL", "SoP", "DFT", "PS", "TOC", "RTM", "LF", "C", "TA", "I", "AA")
space <- c("","","","","","","","","","","")
fullnames <- c("Length of flight (miles)", "Speed of plane (miles/hr)", "Daily flight time (hrs)", "Population served (thousands)", "Total operating costs (cents per revenue ton-mile)", "Revenue tons per aircraft mile", "Ton-mile load factor (proportion)", "Available capacity (tons per mile)", "Total assets ($100,000s)", "Investments and special funds ($100,000s)", "Adjusted assets ($100,000s)")
corresp_table <- matrix(data = c(abb,space,fullnames), nrow = 11, ncol = 3)

kable(corresp_table, align='lcr')
```






# Exploratory data analysis

```{r, include=FALSE}
data <- read.delim("airline_costs.dat", header=FALSE, sep="")
colnames <- c("airline","FL", "SoP", "DFT", "PS", "TOC", "RTM", "LF", "C", "TA", "I", "AA")
colnames(data) <- colnames
ncol(data)
nrow(data)
for (i in 1:ncol(data)) print(typeof(data[,i]))
data_ <- data[,2:ncol(data)] #jsp s'il faut mettre la premiere col en rownames ?
rownames(data_) <- data[,1]
data <- data_
summary(data)
```
data 31 x 12
type of the columns = character, integer or double
y = column 5
column 1 = rownames
--> matrix X of 31x10 with one y 31x1



## Univariate graphical

```{r, fig.width=10, fig.height =5, echo=FALSE}
par(mfrow=c(1,2), mar=(c(6,4.1,4.1,2.1))) 
boxplot(data, las=2, main='Boxplots of the data')
boxplot(log(data), las=2, main='Boxplots of the log of the data')

```
Taking the log can be useful because many differences of amplitudes regarding of the columns ???

Take the log of the data
```{r, include=FALSE}
data_log <- log(data)
data_log[,7] <- data[,7]
```


## Univariate numerical

```{r, echo=FALSE}
summary_table <- data.frame()
meantable <- round(mean(data_log[,1]),2)
sdtable <- round(sd(data_log[,1]),2)
madtable <- round(mad(data_log[,1]),2)
for (i in 2:ncol(data_log)){
  meantable<- c(meantable,round(mean(data_log[,i]),2))
  sdtable <- c(sdtable,round(sd(data_log[,i]),2))
  madtable <- c(madtable,round(mad(data_log[,i]),2))
}

summary_table <- rbind(summary_table, meantable)
summary_table <- rbind(summary_table, sdtable)
summary_table <- rbind(summary_table, madtable)
names(summary_table) <- c("Length of flight", "Speed of plane", "Daily flight time", "Population served", "Total operating cost", "Revenue tons per aircraft mile", "Ton-mile load factor", "Available Cacity", "Total assets", "Investments and special funds", "Adjusted assets")
rownames(summary_table) <- c("Mean", "SD", "MAD")
kable(summary_table[,1:5],align='cccccc') 
kable(summary_table[,6:11],align='ccccccc')
```

## Bivariate numerical (correlations)

```{r, fig.width=5, fig.height =5, echo=FALSE, message=FALSE, warning=FALSE}
#Numerical part

#install.packages("Hmisc")
library(Hmisc)
#install.packages("corrplot")
library(corrplot)
#Numerical
#data_cor <- cor(data)
#rcor <- rcorr(as.matrix(data))
#corrplot(data_cor)

data_cor_log <- cor(data_log)
#rcor <- rcorr(as.matrix(log(data))
corrplot(data_cor_log)
```
These plots image the correlation values between each feature. Indeed, log data show higher correlation values. (For numerical part of criteria)

## Bivariate graphical

```{r, fig.width=7, fig.height =7, echo=FALSE}
pairs(data_log)
```
It seems to have more correlation when taking the log of the data ; more straight lines


# Model fitting

```{r, include=FALSE}
#cost_formula <-  data$TOC ~ data$FL + data$SoP + data$DFT + data$PS + data$RTM + data$LF + data$C + data$TA + data$I + data$AA
#cost.lm <- lm(cost_formula, data=data)
#summary(cost.lm)

#cost_formula <-  data_log$TOC ~ data_log$FL + data_log$SoP + data_log$DFT + data_log$PS + data_log$RTM + data_log$LF + data_log$C + data_log$TA + data_log$I + data_log$AA
cost_formula <-  data_log$TOC ~ .
cost.lm_log <- lm(cost_formula, data=data_log)
s <- summary(cost.lm_log)
rsq <- s$r.squared
arsq <- s$adj.r.squared
coeff <- cost.lm_log$coefficients
```
Response for log data:
According to the summary, the equation is the following: 

$TOC = \hat{\beta_0} + \hat{\beta_1} \times FL + \hat{\beta_2} \times SoP + \hat{\beta_3} \times DFT + \hat{\beta_4} \times PS + \hat{\beta_5} \times RTM + \hat{\beta_6} \times LF + \hat{\beta_7} \times C + \hat{\beta_8} \times TA + \hat{\beta_9} \times I + \hat{\beta_{10}} \times AA$

$TOC = `r round(coeff[1],2)` + (`r round(coeff[2],2)` \times FL) + (`r round(coeff[3],2)` \times SoP) + (`r round(coeff[4],2)` \times DFT) + (`r round(coeff[5],2)` \times PS) + (`r round(coeff[6],2)` \times RTM) + (`r round(coeff[7],2)` \times LF) + (`r round(coeff[8],2)` \times C) + (`r round(coeff[9],2)` \times TA) + (`r round(coeff[10],2)` \times I) + (`r round(coeff[11],2)` \times AA$

$R^2 = `r round(rsq,2)`$ and adjusted $R^2 = `r round(arsq,2)`$ that are high results. 

According to the hypotheses ($H_0: \beta_0 = ... = \beta_{10} = 0$ and $H_1:$ at least one non-zero parameter), the p-value is equal to $1.862*10^{-13} < \alpha = 0.05$. The null hypothesis is rejected. 



# Model assessment

```{r, echo=FALSE}
#layout(matrix(1:6,ncol=3))
#plot(cost.lm, which = c(1,2,3,4,5,6) )   #bad results !!

#log data
layout(matrix(1:6,ncol=3))
plot(cost.lm_log, which = c(1,2,3,4,5,6) )


```
Assumptions (from report criteria):
1. errors have mean 0
2. errors are homoscedastic (same variance)
3. errors are uncorrelated
4. errors are normally distributed

FOR LOG DATA: 
Normal QQ plot shows that absolute values of standardized residuals reach approximately 3 at most, and that no particular deviation from theoretical normal distribution (data follow the theoretical straight line). 

From Residuals vs. fitted plot, we can observe that residuals are spread around a horizontal line at approx. 0. No non-linear relation are present in the model. 

Scale-location allows to observe homoscedasticity. Until fitted value 5, the points are randomly spread and the line is horizontal which affirms the homoscedasticity. After 5, there is some variances, however in a general view the line is quite horizontal. 

Residuals vs. leverage allows to identify potential influencor outliers. We can observe that NorthEast and lake central are out of the cook distance (cook's distance higher than 1 (cook's distance plot)) and have influence on the regression.


https://data.library.virginia.edu/diagnostic-plots/ (explication comment interprÃ©ter les graphs)

# Final estimated model


# Conclusions
